setwd("C:/Users/marti/OneDrive - Nova SBE/Nova/Master's in Business Analytics/Disciplinas/2nd Semester/t1/Network Analytics/Group Work")
library(data.table)
library(igraph)
load("nda-dating-likes.RData")
library(data.table)
library(ggplot2)
library(igraph)
load("nda-dating-likes.RData")
# <answer here>
# <answer here>
# <answer here>
# <answer here>
# Remove the instances where sender_user_id is equal to receiver_user_id (assumed
# to be faulty)
dt.likes.clean <- dt.likes[!(sender_user_id == receiver_user_id), ]
# Create a directed graph representing the likes network
dt.likes.g <- dt.likes.clean[, list(sender_user_id, receiver_user_id)]
g.likes.directed <- graph_from_data_frame(d = dt.likes.g, directed = TRUE)
# Plot a sample (original graph is too big to plot)
sample.nodes <- sample(V(g.likes.directed), 500)
g.sample <- induced_subgraph(g.likes.directed, vids = sample.nodes)
plot(g.sample, vertex.label = NA, vertex.size = 10, edge.arrow.size = 0.5)
# Compute the clustering coefficient
average.cluster.directed <- transitivity(g.likes.directed, type="average")
print("Clustering Coefficient:")
print(average.cluster.directed)
# A: Clustering coefficient is 0.0004102289
# Check if dt.users has duplicated user_id or missing gender
print("Number of rows with duplicated user_id in dt.users:")
print(sum(duplicated(dt.users$user_id)))
print("Number of rows with missing gender in dt.users:")
print(sum(is.na(dt.users$gender)))
# Merge likes data table and gender data
dt.merged <- merge(dt.likes.clean, dt.users[, list(user_id, gender)],
by.x = "sender_user_id", by.y = "user_id")
setnames(dt.merged, "gender", "sender_gender")
dt.merged <- merge(dt.merged, dt.users[, list(user_id, gender)],
by.x = "receiver_user_id", by.y = "user_id")
setnames(dt.merged, "gender", "receiver_gender")
# Subset for same gender likes
dt.gender.same <- dt.merged[sender_gender == receiver_gender, ]
# Remove duplicate senders and users that like themselves
dt.gender.same.unique <- unique(dt.gender.same, by = "sender_user_id")
# Compute the number of individuals that like the same gender
t.gender.count.same <- table(dt.gender.same.unique$sender_gender)
print("Total individuals that like the same gender:")
lgb.count <- sum(t.gender.count.same)
print(lgb.count)
print("Number of individuals that like the same gender, by gender:")
print(t.gender.count.same)
# Check if all the users in dt.users are in dt.likes (before calc. proportions)
print("Number of users in dt.users not in dt.likes:")
number.users <- dt.users[!((dt.users$user_id %in% dt.likes$receiver_user_id) |
(dt.users$user_id %in% dt.likes$sender_user_id)), .N]
print(number.users)
# Compute proportions
print("Proportion of individuals that like the same gender:")
user.count <- dt.users[, .N]
print(lgb.count / user.count)
print("Proportion of individuals that like the same gender by gender:")
t.gender.count.all <- table(dt.users$gender)
t.gender.proportion.same <- t.gender.count.same / t.gender.count.all
print(t.gender.proportion.same)
# A: Male - 257 (3.8%); Female - 166 (2%); Total - 423 (2.81%)
# Transform the directed graph built in question 1 into an undirected graph
g.likes.undirected <- as.undirected(g.likes.directed, mode = "mutual")
vertices.filter <- V(g.likes.undirected)[degree(g.likes.undirected) != 0]
g.matches <- induced_subgraph(g.likes.undirected, vids = vertices.filter)
# Plot a sample (original graph is too big to plot)
sample.nodes <- sample(V(g.matches), 500)
g.sample <- induced_subgraph(g.matches, vids = sample.nodes)
plot(g.sample, vertex.label = NA, vertex.size = 3,
edge.arrow.size = 0.5)
# Compute the clustering coefficient
average.cluster.undirected <- transitivity(g.matches, type="average")
print("Clustering Coefficient:")
print(average.cluster.undirected)
# A: Clustering coefficient is 0.0002786879
# Store the number of Vertices and Edges of the matches graph in variables
number.vertices <- vcount(g.matches)
number.edges <- ecount(g.matches)
# Build a random network
g.random <- sample_gnm(number.vertices, number.edges)
# Build the scale-free networks using preferential attachment
# Define the m parameter as n edges / n vertices to get a comparable network
m.pref <- median(degree(g.matches))
g.sf.pa.p2 <- sample_pa(number.vertices, power = 2, m = m.pref,
directed = FALSE)
g.sf.pa.p3 <- sample_pa(number.vertices, power = 3, m = m.pref,
directed = FALSE)
# Build the scale-free networks using the fitness model
g.sf.fit.p2 <- sample_fitness_pl(number.vertices, number.vertices,
exponent.in = -1, exponent.out = 2)
g.sf.fit.p3 <- sample_fitness_pl(number.vertices, number.vertices,
exponent.in = -1, exponent.out = 3)
# Build the pure networks with arbitrary number of vertices and edges
g.type.random <- sample_gnp(1000, p = 0.1)
g.type.sf.p2 <- sample_pa(1000, power = 2, m = 5)
g.type.sf.p3 <- sample_pa(1000, power = 3, m = 5)
# Compute the degrees and put them together in a data table
dt.degree.match <- data.table(degree = degree(g.matches),
network = "Matches")
dt.degree.random <- data.table(degree = degree(g.random), network = "Random")
dt.degree.pa.p2 <- data.table(degree = degree(g.sf.pa.p2),
network = "Scale-Free PA, Power 2")
dt.degree.pa.p3 <- data.table(degree = degree(g.sf.pa.p3),
network = "Scale-Free PA, Power 3")
dt.degree.fit.p2 <- data.table(degree = degree(g.sf.fit.p2),
network = "Scale-Free Fit, Power 2")
dt.degree.fit.p3 <- data.table(degree = degree(g.sf.fit.p3),
network = "Scale-Free Fit, Power 3")
dt.degree.type.random <- data.table(degree = degree(g.type.random),
network = "Random Type")
dt.degree.type.sf.p2 <- data.table(degree = degree(g.type.sf.p2),
network = "Scale-Free Type, Power 2")
dt.degree.type.sf.p3 <- data.table(degree = degree(g.type.sf.p3),
network = "Scale-Free Type, Power 3")
dt.degree.all <- rbind(dt.degree.match, dt.degree.random, dt.degree.pa.p2,
dt.degree.pa.p3, dt.degree.fit.p2, dt.degree.fit.p3,
dt.degree.type.random, dt.degree.type.sf.p2,
dt.degree.type.sf.p3)
dt.degree.all <- dt.degree.all[, .(count = .N), by = list(degree, network)]
# Plot the degree distribution on a regular scale
l.to.plot <- list("Matches", "Random", "Scale-Free PA, Power 2",
"Scale-Free PA, Power 3", "Scale-Free Fit, Power 2",
"Scale-Free Fit, Power 3", "Random Type",
"Scale-Free Type, Power 2", "Scale-Free Type, Power 3")
l.to.plot <- list("Matches", "Random", "Scale-Free PA, Power 2")
ggplot(dt.degree.all[network %in% l.to.plot], aes(x = degree, y = count,
color = network)) +
geom_line() +
scale_x_log10() + scale_y_log10() +
theme_minimal() +
labs(title = "Degree Distributions",
x = "Degree (log scale)",
y = "Count (log scale)",
color = "Network Type") +
theme(legend.position = "bottom")
l.to.plot <- list("Scale-Free PA, Power 2")
ggplot(dt.degree.all[network %in% l.to.plot], aes(x = degree, y = count,
color = network)) +
geom_line() +
scale_x_log10() + scale_y_log10() +
theme_minimal() +
labs(title = "Degree Distributions",
x = "Degree (log scale)",
y = "Count (log scale)",
color = "Network Type") +
theme(legend.position = "bottom")
l.to.plot <- list("Scale-Free Type, Power 2")
ggplot(dt.degree.all[network %in% l.to.plot], aes(x = degree, y = count,
color = network)) +
geom_line() +
scale_x_log10() + scale_y_log10() +
theme_minimal() +
labs(title = "Degree Distributions",
x = "Degree (log scale)",
y = "Count (log scale)",
color = "Network Type") +
theme(legend.position = "bottom")
g.type.sf.p2 <- sample_pa(1000, power = 1, m = 5)
ggplot(dt.degree.all[network %in% l.to.plot], aes(x = degree, y = count,
color = network)) +
geom_line() +
scale_x_log10() + scale_y_log10() +
theme_minimal() +
labs(title = "Degree Distributions",
x = "Degree (log scale)",
y = "Count (log scale)",
color = "Network Type") +
theme(legend.position = "bottom")
g.type.sf.p2 <- sample_pa(1000, power = 1, m =20)
l.to.plot <- list("Scale-Free Type, Power 2")
ggplot(dt.degree.all[network %in% l.to.plot], aes(x = degree, y = count,
color = network)) +
geom_line() +
scale_x_log10() + scale_y_log10() +
theme_minimal() +
labs(title = "Degree Distributions",
x = "Degree (log scale)",
y = "Count (log scale)",
color = "Network Type") +
theme(legend.position = "bottom")
